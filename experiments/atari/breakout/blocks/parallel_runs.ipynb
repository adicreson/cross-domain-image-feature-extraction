{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa10e55ac7f097b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "    # Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "990905f50fea55f1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:18:32.118507100Z",
     "start_time": "2024-04-04T19:18:21.290891800Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import multiprocessing\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import CallbackList, EvalCallback\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, VecTransposeImage\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "from feature_extraction.callbacks.wandb_on_training_end_callback import WandbOnTrainingEndCallback\n",
    "from feature_extraction.feature_extractors.resnet.block_feature_extractor import BlockFeatureExtractor\n",
    "from feature_extraction.wrappers.vec_feature_extractor import VecFeatureExtractor\n",
    "from utils import linear_schedule, make_resnet_atari_env\n",
    "from collections import OrderedDict\n",
    "\n",
    "from torchvision.models import ResNet50_Weights, resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ddbbcf6a2b1455",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Method for creating a new configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e91f377ae09d36e5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:18:32.130035100Z",
     "start_time": "2024-04-04T19:18:32.123137Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_config(project_name, run_name):\n",
    "    \"\"\"\n",
    "    Creates a new configuration as an OrderedDict with a specified project and run name,\n",
    "    and sets the training_seed and evaluation_seed to random integers,\n",
    "    while using a predefined set of default settings for the rest.\n",
    "\n",
    "    Parameters:\n",
    "    - project_name (str): Name of the project.\n",
    "    - run_name (str): Name of the run.\n",
    "\n",
    "    Returns:\n",
    "    - OrderedDict: A new configuration dictionary with the specified project and run names,\n",
    "                   random seeds, and default settings for other parameters.\n",
    "    \"\"\"\n",
    "    training_seed = random.randint(0, 9999) # Should later on be same for all experiments to ensure comparability\n",
    "    evaluation_seed = random.randint(0, 9999) # Should later on be same for all experiments to ensure comparability\n",
    "\n",
    "    default_config = OrderedDict([\n",
    "        # Environment settings\n",
    "        ('project_name', project_name),\n",
    "        ('run_name', run_name),\n",
    "        ('env_id', \"BreakoutNoFrameskip-v4\"),\n",
    "        ('n_envs', 8),\n",
    "        ('env_wrapper', ['stable_baselines3.common.atari_wrappers.AtariWrapper']),\n",
    "        ('frame_stack', 4),\n",
    "        ('training_seed', 12),\n",
    "        ('evaluation_seed', 14),\n",
    "        \n",
    "        # Algorithm and policy settings\n",
    "        ('algo', 'PPO'),\n",
    "        ('policy', 'MlpPolicy'),\n",
    "        \n",
    "        # Training hyperparameters\n",
    "        ('batch_size', 256),\n",
    "        ('n_steps', 128),\n",
    "        ('n_epochs', 4),\n",
    "        ('n_timesteps', 1_000),\n",
    "        ('learning_rate', 0.00025),\n",
    "        ('learning_rate_schedule', 'linear'),\n",
    "        ('clip_range', 0.1),\n",
    "        ('clip_range_schedule', 'linear'),\n",
    "        ('ent_coef', 0.01),\n",
    "        ('vf_coef', 0.5),\n",
    "        ('normalize_advantage', False),\n",
    "        \n",
    "        # Evaluation and logging settings\n",
    "        ('n_eval_episodes', 5),\n",
    "        ('record_n_episodes', 10),\n",
    "        ('n_final_eval_episodes', 25),\n",
    "        ('log_frequency', 1024),\n",
    "        \n",
    "        # Other settings\n",
    "        ('verbose', 1)\n",
    "    ])\n",
    "    \n",
    "\n",
    "    return default_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8dfb31a922ebdc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Method for running a single experiment with a configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "703ef7863fdada08",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:18:32.162309300Z",
     "start_time": "2024-04-04T19:18:32.137594300Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment(config):\n",
    "    wandb.login()\n",
    "\n",
    "    # Initialize the wandb run\n",
    "    wandb.init(project=config['project_name'],\n",
    "                     name=config['run_name'],\n",
    "                     config=config, save_code=True,\n",
    "                     sync_tensorboard=True)\n",
    "    \n",
    "    config = wandb.config\n",
    "    \n",
    "    log_dir = f\"logs/{config.run_name}\"\n",
    "    #feature_extractor = StageFeatureExtractor()\n",
    "    \n",
    "    model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Device: \", device)\n",
    "    model.to(device)\n",
    "    feature_extractor = BlockFeatureExtractor(model, 1, log_dir, log_to_wandb=True)\n",
    "    \n",
    "    \n",
    "    # Create Evaluation Environment\n",
    "    vec_eval_env = make_resnet_atari_env(\n",
    "        config.env_id,\n",
    "        n_envs=config.n_envs,\n",
    "        seed=config.evaluation_seed,\n",
    "    )\n",
    "    \n",
    "    print(\"original_observation_space\", vec_eval_env.observation_space.shape)\n",
    "    \n",
    "    vec_eval_env = VecTransposeImage(vec_eval_env)\n",
    "    print(\"vec_transpose_obs_space\", vec_eval_env.observation_space.shape)\n",
    "\n",
    "    vec_eval_env = VecFrameStack(vec_eval_env, n_stack=config.frame_stack)\n",
    "    print(\"vec_frame_stack_obs_space\", vec_eval_env.observation_space.shape)\n",
    "\n",
    "    vec_eval_env = VecFeatureExtractor(vec_eval_env, feature_extractor, n_stacks=config.frame_stack)\n",
    "    print(\"vec_feature_extractor_obs_space\", vec_eval_env.observation_space.shape)\n",
    "    \n",
    "    # Create Training Environment    \n",
    "    vec_train_env = make_resnet_atari_env(config.env_id, n_envs=config.n_envs, seed=config.training_seed)\n",
    "    vec_train_env = VecTransposeImage(vec_train_env)\n",
    "    vec_train_env = VecFrameStack(vec_train_env, n_stack=config.frame_stack)\n",
    "    vec_train_env = VecFeatureExtractor(vec_train_env, feature_extractor, n_stacks=config.frame_stack)\n",
    "\n",
    "    # Define the keys for PPO-specific hyperparameters\n",
    "    ppo_params_keys = [\n",
    "        'batch_size',\n",
    "        'ent_coef',\n",
    "        'n_epochs',\n",
    "        'n_steps',\n",
    "        'policy',\n",
    "        'vf_coef',\n",
    "        'normalize_advantage',\n",
    "    ]\n",
    "\n",
    "    # Filter the config dictionary to extract only the PPO hyperparameters\n",
    "    ppo_hyperparams = {key: config[key] for key in ppo_params_keys if key in config}\n",
    "\n",
    "    # Additional hyperparameters not in the initial filter that require custom handling\n",
    "    learning_rate_schedule = linear_schedule(2.5e-4)\n",
    "    clip_range_schedule = linear_schedule(0.1)\n",
    "\n",
    "    # Instantiate the PPO model with the specified hyperparameters and environment\n",
    "    model = PPO(\n",
    "        **ppo_hyperparams,\n",
    "        learning_rate=learning_rate_schedule,\n",
    "        clip_range=clip_range_schedule,\n",
    "        env=vec_train_env,\n",
    "        verbose=1,\n",
    "        tensorboard_log=f\"{log_dir}\",\n",
    "    )\n",
    "\n",
    "    # Save best model\n",
    "    eval_callback = EvalCallback(\n",
    "        eval_env=vec_eval_env,\n",
    "        eval_freq=max(config.log_frequency // config.n_envs, 1),\n",
    "        n_eval_episodes=config.n_eval_episodes,\n",
    "        best_model_save_path=log_dir,\n",
    "        log_path=log_dir,\n",
    "        deterministic=True,\n",
    "        render=False,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Needs to be changed, so it uses run instead of wandb\n",
    "    wandb_callback = WandbCallback(\n",
    "        verbose=1,\n",
    "        gradient_save_freq=256,\n",
    "    )\n",
    "\n",
    "    wandb_on_training_end_callback = WandbOnTrainingEndCallback(\n",
    "        model=model,\n",
    "        eval_env=vec_eval_env,\n",
    "        log_dir=log_dir,\n",
    "        n_eval_episodes=config.n_final_eval_episodes,\n",
    "        record_n_episodes=config.record_n_episodes,\n",
    "    )\n",
    "    callbacks = CallbackList([wandb_callback, eval_callback, wandb_on_training_end_callback])\n",
    "\n",
    "    model.learn(\n",
    "        total_timesteps=config.n_timesteps,\n",
    "        callback=callbacks,\n",
    "    )\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd40b133aa74c6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Method for running multiple experiments with a configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b972917656c5e9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:18:32.163729800Z",
     "start_time": "2024-04-04T19:18:32.144861200Z"
    }
   },
   "outputs": [],
   "source": [
    "# def run_experiments_in_parallel(config_list):\n",
    "#     processes = []\n",
    "#     for config in config_list:\n",
    "#         p = multiprocessing.Process(target=run_experiment, args=(config,))\n",
    "#         p.start()\n",
    "#         processes.append(p)\n",
    "#         time.sleep(60) # Sleep to avoid file write conflicts\n",
    "# \n",
    "#     for p in processes:\n",
    "#         p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21476eb484eed70",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d8d2eb7eba7780",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T19:18:32.163729800Z",
     "start_time": "2024-04-04T19:18:32.155649400Z"
    }
   },
   "outputs": [],
   "source": [
    "# configs = []\n",
    "# runs = [\"breakout_block1\"]\n",
    "# \n",
    "# for run in runs:\n",
    "#     timestamp = datetime.datetime.now().strftime('_%Y-%m-%d_%H-%M-%S')\n",
    "#     \n",
    "#     project_name = \"tmp\"\n",
    "#     run_name = run + timestamp\n",
    "#     \n",
    "#     new_config = create_config(project_name, run_name)\n",
    "#     configs.append(new_config)\n",
    "# \n",
    "# # Run experiments in parallel\n",
    "# run_experiments_in_parallel(configs)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: mamdollah (feature_extraction). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.5"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\Lenovo\\PycharmProjects\\Global-Feature-Extraction\\experiments\\atari\\breakout\\blocks\\wandb\\run-20240404_211834-so7qieiy</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/feature_extraction/tmp/runs/so7qieiy/workspace' target=\"_blank\">breakout_block1__2024-04-04_21-18-32</a></strong> to <a href='https://wandb.ai/feature_extraction/tmp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/feature_extraction/tmp' target=\"_blank\">https://wandb.ai/feature_extraction/tmp</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/feature_extraction/tmp/runs/so7qieiy/workspace' target=\"_blank\">https://wandb.ai/feature_extraction/tmp/runs/so7qieiy/workspace</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n",
      "original_observation_space (224, 224, 3)\n",
      "vec_transpose_obs_space (3, 224, 224)\n",
      "vec_frame_stack_obs_space (12, 224, 224)\n",
      "vec_feature_extractor_obs_space (1, 1024)\n",
      "Using cpu device\n",
      "Logging to logs/breakout_block1__2024-04-04_21-18-32\\PPO_1\n",
      "Saving original image...\n",
      "Image_transposed shape:  (224, 224, 3)\n",
      "Original image saved.\n",
      "Tensor image shape:  torch.Size([3, 224, 224])\n",
      "Tensor image saved.\n",
      "Saving tensor_0\n",
      "Original image saved.\n",
      "Saving feature embeddings...\n",
      "Shape of feature embeddings:  torch.Size([1, 256, 56, 56])\n",
      "Feature embeddings saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Images sizes do not match. This will causes images to be display incorrectly in the UI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 649      |\n",
      "|    mean_reward     | 2.2      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 516      |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 4        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 206      |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\PycharmProjects\\Global-Feature-Extraction\\venv\\Lib\\site-packages\\stable_baselines3\\common\\distributions.py:87: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if deterministic:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n"
     ]
    }
   ],
   "source": [
    "run_experiment(create_config(\"tmp\", \n",
    "                             f\"breakout_block1_{datetime.datetime.now().strftime('_%Y-%m-%d_%H-%M-%S')}\"\n",
    "                             )\n",
    "               )\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-04T19:18:32.162309300Z"
    }
   },
   "id": "d9c2020583cdb5f1",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
