{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This file is for creating the benchmark, with stacked frames."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48ae7a254094dc4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# install relevant packages"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2917de89eb849f74"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#!pip install 'gymnasium[atari]'\n",
    "#!pip install 'gymnasium[accept-rom-license]'\n",
    "#!pip install 'opencv-python'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T22:39:31.644144121Z",
     "start_time": "2024-03-12T22:39:31.642067525Z"
    }
   },
   "id": "c0ba8aa7682bc76e",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# import relevant packages"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee775089098578a5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 17:01:40.281772: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-13 17:01:40.281830: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-13 17:01:40.283129: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-13 17:01:40.289443: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-13 17:01:41.189730: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, VecTransposeImage\n",
    "from stable_baselines3 import A2C, PPO\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, EveryNTimesteps\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from utils import evaluate_policy\n",
    "import wandb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T16:01:43.095724565Z",
     "start_time": "2024-03-13T16:01:38.007661544Z"
    }
   },
   "id": "e9bbbd1ea019cb71",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Settings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29738fd8c353a5a1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33madicreson\u001B[0m (\u001B[33mfeature_extraction\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n",
    "# cceb2653e8e4543a510e4c872213e68ea45cb706\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T16:01:49.508528941Z",
     "start_time": "2024-03-13T16:01:47.761851882Z"
    }
   },
   "id": "1defb9dccdfd4a9a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.4"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/maliti/Prog/Global-Feature-Extraction/experiments/atari/breakout/benchmark/wandb/run-20240313_170202-vkxw2xn8</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/feature_extraction/a2c_breakout_benchmark_framestack/runs/vkxw2xn8' target=\"_blank\">divine-leaf-1</a></strong> to <a href='https://wandb.ai/feature_extraction/a2c_breakout_benchmark_framestack' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/feature_extraction/a2c_breakout_benchmark_framestack' target=\"_blank\">https://wandb.ai/feature_extraction/a2c_breakout_benchmark_framestack</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/feature_extraction/a2c_breakout_benchmark_framestack/runs/vkxw2xn8' target=\"_blank\">https://wandb.ai/feature_extraction/a2c_breakout_benchmark_framestack/runs/vkxw2xn8</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "progress_bar = False\n",
    "train_model = True\n",
    "eval_model = True\n",
    "save_name = \"a2c_breakout_benchmark_framestack\"\n",
    "\n",
    "\n",
    "config = dict(\n",
    "    env_id=\"ALE/Breakout-v5\",\n",
    "    algorithm='PPO',\n",
    "    #Hyperparams\n",
    "    policy=\"CnnPolicy\",\n",
    "    learning_rate='lin_2.5e-4',\n",
    "    n_steps=128,\n",
    "    batch_size=256,\n",
    "    n_epochs=4,\n",
    "    n_envs=8,\n",
    "    n_timesteps=10_000_000.0,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    clip_range='lin_0.1',\n",
    "    clip_range_vf=None,\n",
    "    normalize_advantage=True,\n",
    "    normalize=False,\n",
    "    ent_coef=0.01,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    use_sde=False,\n",
    "    sde_sample_freq=-1,\n",
    "    rollout_buffer_class=None,\n",
    "    rollout_buffer_kwargs=None,\n",
    "    target_kl=None,\n",
    "    stats_window_size=100,\n",
    "    tensorboard_log=None,\n",
    "    policy_kwargs=None,\n",
    "    verbose=0,\n",
    "    seed=None,\n",
    "    device='auto',\n",
    "    _init_setup_model=True,\n",
    "    env_wrapper='stable_baselines3.common.atari_wrappers.AtariWrapper',\n",
    "    frame_stack=4,\n",
    ")\n",
    "\n",
    "wandb.init(project=save_name, config=config)\n",
    "config = wandb.config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T16:02:03.815611560Z",
     "start_time": "2024-03-13T16:02:02.471725427Z"
    }
   },
   "id": "83aa1191533c44b5",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create callbacks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b96f4e70a9af239e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "# Every n steps.\n",
    "# checkpoint_on_event = CheckpointCallback(save_freq=1, save_path=\"./logs/\")\n",
    "# callback = EveryNTimesteps(n_steps=500, callback=checkpoint_on_event)\n",
    "vec_eval_env = make_atari_env(config.env_id, n_envs=config.n_envs)\n",
    "vec_eval_env = VecFrameStack(vec_eval_env, n_stack=config.frame_stack)\n",
    "vec_eval_env = VecTransposeImage(vec_eval_env)\n",
    "\n",
    "# Save best model\n",
    "callback = EvalCallback(vec_eval_env, best_model_save_path=\"./logs/\",\n",
    "                             log_path=\"./logs/\", eval_freq=500,\n",
    "                             deterministic=True, render=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T22:39:37.814875260Z",
     "start_time": "2024-03-12T22:39:37.311993935Z"
    }
   },
   "id": "3f47fb1c3e907b7a",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create vectorized env and stack frames"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8b15b4e06d109cf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vec_train_env = make_atari_env(config.env_id, n_envs=config.n_envs)\n",
    "# Frame-stacking with 4 frames\n",
    "vec_train_env = VecFrameStack(vec_train_env, n_stack=config.frame_stack)\n",
    "vec_train_env = VecTransposeImage(vec_train_env)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T22:39:38.275028113Z",
     "start_time": "2024-03-12T22:39:37.936944381Z"
    }
   },
   "id": "6228fe1f1f1916f5",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create model, learn and save"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92e71946af36c557"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Eval num_timesteps=2000, episode_reward=2.40 +/- 1.50\n",
      "Episode length: 260.60 +/- 62.68\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 261      |\n",
      "|    mean_reward        | 2.4      |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | 0.928    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.0545   |\n",
      "|    value_loss         | 0.0326   |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 236      |\n",
      "|    ep_rew_mean     | 1.8      |\n",
      "| time/              |          |\n",
      "|    fps             | 164      |\n",
      "|    iterations      | 100      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 2000     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=2.60 +/- 0.80\n",
      "Episode length: 267.00 +/- 46.72\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 267      |\n",
      "|    mean_reward        | 2.6      |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.498   |\n",
      "|    explained_variance | -0.291   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.00938  |\n",
      "|    value_loss         | 0.666    |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 247      |\n",
      "|    ep_rew_mean     | 2.09     |\n",
      "| time/              |          |\n",
      "|    fps             | 173      |\n",
      "|    iterations      | 200      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 4000     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=1.20 +/- 1.47\n",
      "Episode length: 5583.80 +/- 10708.24\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 5.58e+03 |\n",
      "|    mean_reward        | 1.2      |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.01    |\n",
      "|    explained_variance | 0.884    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.159    |\n",
      "|    value_loss         | 0.0581   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 251      |\n",
      "|    ep_rew_mean     | 2.22     |\n",
      "| time/              |          |\n",
      "|    fps             | 46       |\n",
      "|    iterations      | 300      |\n",
      "|    time_elapsed    | 128      |\n",
      "|    total_timesteps | 6000     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=1.60 +/- 1.36\n",
      "Episode length: 10963.40 +/- 13093.84\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 1.1e+04  |\n",
      "|    mean_reward        | 1.6      |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.04    |\n",
      "|    explained_variance | 0.979    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.0209  |\n",
      "|    value_loss         | 0.00789  |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 249      |\n",
      "|    ep_rew_mean     | 2.2      |\n",
      "| time/              |          |\n",
      "|    fps             | 35       |\n",
      "|    iterations      | 400      |\n",
      "|    time_elapsed    | 228      |\n",
      "|    total_timesteps | 8000     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=2.00 +/- 1.10\n",
      "Episode length: 5613.80 +/- 10693.11\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 5.61e+03 |\n",
      "|    mean_reward        | 2        |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.09    |\n",
      "|    explained_variance | 0.981    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -0.0271  |\n",
      "|    value_loss         | 0.0115   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 250      |\n",
      "|    ep_rew_mean     | 2.21     |\n",
      "| time/              |          |\n",
      "|    fps             | 29       |\n",
      "|    iterations      | 500      |\n",
      "|    time_elapsed    | 336      |\n",
      "|    total_timesteps | 10000    |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    model = PPO(config.policy, vec_train_env, verbose=1)\n",
    "    model.learn(total_timesteps=config.n_timesteps, callback=callback, progress_bar=progress_bar)\n",
    "    model.save(save_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T22:45:14.919544707Z",
     "start_time": "2024-03-12T22:39:38.286261262Z"
    }
   },
   "id": "28259fafc81561b7",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load and evaluate Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "163eabb49c4390ca"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if eval_model:\n",
    "    model = PPO.load(\"logs/best_model.zip\", env=vec_eval_env)\n",
    "    mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=2, render=False, fps=30)\n",
    "    print(mean_reward, std_reward)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T22:45:14.928834661Z",
     "start_time": "2024-03-12T22:45:14.919773417Z"
    }
   },
   "id": "5c082cbec6e990a3",
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
