{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 12:54:32.708798: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-05 12:54:32.708945: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-05 12:54:32.747863: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-05 12:54:32.823875: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-05 12:54:34.188179: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.utils import set_random_seed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T11:54:36.564252445Z",
     "start_time": "2024-02-05T11:54:28.885556909Z"
    }
   },
   "id": "5c43948bb11dd4d3"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-26T11:38:42.660743468Z",
     "start_time": "2024-01-26T11:38:42.596410898Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "make_vec_env() got an unexpected keyword argument 'render_mode'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m env_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCartPole-v1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      2\u001B[0m num_cpu \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m  \u001B[38;5;66;03m# Number of processes to use\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m vec_env \u001B[38;5;241m=\u001B[39m \u001B[43mmake_vec_env\u001B[49m\u001B[43m(\u001B[49m\u001B[43menv_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_envs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_cpu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvec_env_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mSubprocVecEnv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrender_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhuman\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m model \u001B[38;5;241m=\u001B[39m A2C(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMlpPolicy\u001B[39m\u001B[38;5;124m\"\u001B[39m, vec_env, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      7\u001B[0m model\u001B[38;5;241m.\u001B[39mlearn(total_timesteps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m500000\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: make_vec_env() got an unexpected keyword argument 'render_mode'"
     ]
    }
   ],
   "source": [
    "env_id = \"CartPole-v1\"\n",
    "num_cpu = 8  # Number of processes to use\n",
    "\n",
    "vec_env = make_vec_env(env_id, n_envs=num_cpu, seed=0, vec_env_cls=SubprocVecEnv)\n",
    "\n",
    "model = A2C(\"MlpPolicy\", vec_env, verbose=1)\n",
    "model.learn(total_timesteps=500000)\n",
    "\n",
    "model.save(\"a2c_cartpole\")\n",
    "\n",
    "obs = vec_env.reset()\n",
    "for _ in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    vec_env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Episode 1 terminated\n",
      "Accumulated Reward: 500.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 19\u001B[0m\n\u001B[1;32m     15\u001B[0m accumulated_reward \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m finished:\n\u001B[0;32m---> 19\u001B[0m     frame \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)  \u001B[38;5;66;03m# Add a small delay to slow down rendering\u001B[39;00m\n\u001B[1;32m     21\u001B[0m     action \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(observation)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/Prog/Global-Feature-Extraction/venv/lib/python3.10/site-packages/gymnasium/core.py:471\u001B[0m, in \u001B[0;36mWrapper.render\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    469\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrender\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m RenderFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mlist\u001B[39m[RenderFrame] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    470\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 471\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Prog/Global-Feature-Extraction/venv/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py:70\u001B[0m, in \u001B[0;36mOrderEnforcing.render\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_disable_render_order_enforcing \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_reset:\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ResetNeeded(\n\u001B[1;32m     67\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot call `env.render()` before calling `env.reset()`, if this is a intended action, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     68\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     69\u001B[0m     )\n\u001B[0;32m---> 70\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Prog/Global-Feature-Extraction/venv/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py:67\u001B[0m, in \u001B[0;36mPassiveEnvChecker.render\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m env_render_passive_checker(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 67\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Prog/Global-Feature-Extraction/venv/lib/python3.10/site-packages/gymnasium/envs/classic_control/cartpole.py:302\u001B[0m, in \u001B[0;36mCartPoleEnv.render\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    300\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrender_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    301\u001B[0m     pygame\u001B[38;5;241m.\u001B[39mevent\u001B[38;5;241m.\u001B[39mpump()\n\u001B[0;32m--> 302\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtick\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrender_fps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    303\u001B[0m     pygame\u001B[38;5;241m.\u001B[39mdisplay\u001B[38;5;241m.\u001B[39mflip()\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrender_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrgb_array\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import time\n",
    "\n",
    "env = gym.make('CartPole-v1', render_mode=\"human\")\n",
    "#model.set_parameters(\"a2c_cartpole\", env)\n",
    "model = A2C(\"MlpPolicy\", env, verbose=1)\n",
    "model.set_parameters(\"a2c_cartpole\", env)\n",
    "\n",
    "\n",
    "episodes = 10\n",
    "\n",
    "for episode in range(1, episodes+1):    \n",
    "    observation, info = env.reset(seed=42)\n",
    "    finished = False\n",
    "    accumulated_reward = 0\n",
    "    \n",
    "    \n",
    "    while not finished:\n",
    "        frame = env.render()\n",
    "        time.sleep(0.01)  # Add a small delay to slow down rendering\n",
    "        action = model.predict(observation)[0]\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        accumulated_reward += reward\n",
    "        finished = terminated or truncated\n",
    "\n",
    "        if terminated or truncated:\n",
    "            observation, info = env.reset()\n",
    "            print(\"Episode {} terminated\".format(episode))\n",
    "            print(\"Accumulated Reward: {}\".format(accumulated_reward))\n",
    "\n",
    "env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T11:55:03.175902358Z",
     "start_time": "2024-02-05T11:54:37.402029373Z"
    }
   },
   "id": "e1cff84769deb79"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
